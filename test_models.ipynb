{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.pipeline import *\n",
    "from src.utils import PropertyDict, print_conversation\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "import pandas as pd\n",
    "from src.evaluation import evaluate_conversation\n",
    "from src.train import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = PropertyDict(\n",
    "    seed=42,\n",
    "    checkpoint_name=\"bert_tiny\",\n",
    "    model_name=\"bert_tiny\",\n",
    "    model_type=\"encoder_decoder\",\n",
    "    initialize_cross_attention=True,\n",
    "    # yng_loss_weight=1.0,\n",
    "    # rationale_loss_weight=1.0,\n",
    "    # generative_loss_weight=1.0,\n",
    "    yng_loss_weight=5.,\n",
    "    rationale_loss_weight=3.,\n",
    "    generative_loss_weight=1.,\n",
    "    batch_size=8,\n",
    "    val_batch_size=16,\n",
    "    generate_batch_size=128,\n",
    "    num_workers=0,\n",
    "    num_epochs=3,\n",
    "    optimizer_name=\"AdamW\",\n",
    "    # learning_rate=5e-3,\n",
    "    learning_rate=2e-5,\n",
    "    loss_learning_rate=1e-1,\n",
    "    scheduler=\"linear\",\n",
    "    warmup_fraction=0.1,\n",
    "    accumulation_steps=1,\n",
    "    gradient_clip = 1.0,\n",
    "    mixed_precision=\"fp16\",\n",
    "    checkpoint_interval=1000,\n",
    "    log_interval=1000,\n",
    "    cpu=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteo-periani\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matteo/uni/nlp/nlp_assignment2/wandb/run-20230825_174752-wr5hrgdm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matteo-periani/nlp_assignment2/runs/wr5hrgdm' target=\"_blank\">rich-haze-15</a></strong> to <a href='https://wandb.ai/matteo-periani/nlp_assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matteo-periani/nlp_assignment2' target=\"_blank\">https://wandb.ai/matteo-periani/nlp_assignment2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matteo-periani/nlp_assignment2/runs/wr5hrgdm' target=\"_blank\">https://wandb.ai/matteo-periani/nlp_assignment2/runs/wr5hrgdm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "Loading cached shuffled indices for dataset at /home/matteo/uni/nlp/nlp_assignment2/data/train/train_no_history/bert_tiny/train/cache-63078ed47e5b4d10.arrow\n",
      "Loading cached shuffled indices for dataset at /home/matteo/uni/nlp/nlp_assignment2/data/train/train_no_history/bert_tiny/validation/cache-6228d23398cad876.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-attention has been initialized with self-attention weights.\n",
      "QAEncoderDecoderModel(\n",
      "  (encoder): QAEncoder(\n",
      "    (encoder): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 128)\n",
      "        (token_type_embeddings): Embedding(2, 128)\n",
      "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-1): 2 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (rationale_head): TokenSelectionHead(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (act_fn): ReLU()\n",
      "      (hidden_to_logit): Linear(in_features=128, out_features=1, bias=False)\n",
      "    )\n",
      "    (yes_no_gen_head): YesNoGenHead(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (act_fn): ReLU()\n",
      "      (hidden_to_logit): Linear(in_features=128, out_features=1, bias=False)\n",
      "      (softmax): Softmax(dim=-2)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (classifier): Linear(in_features=256, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): BertLMHeadModel(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 128)\n",
      "        (token_type_embeddings): Embedding(2, 128)\n",
      "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-1): 2 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): BertOnlyMLMHead(\n",
      "      (predictions): BertLMPredictionHead(\n",
      "        (transform): BertPredictionHeadTransform(\n",
      "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (transform_act_fn): GELUActivation()\n",
      "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (decoder): Linear(in_features=128, out_features=30522, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8025 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 12%|█▏        | 1001/8025 [01:59<9:58:32,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   1000\ttrain loss: 13.0747\tval loss: 8.8147\tlr: 0.000019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2001/8025 [04:01<8:33:15,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   2000\ttrain loss: 7.9149\tval loss: 8.4364\tlr: 0.000017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3001/8025 [06:02<7:05:12,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   3000\ttrain loss: 7.4832\tval loss: 8.3853\tlr: 0.000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4001/8025 [08:01<5:36:33,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   4000\ttrain loss: 7.3497\tval loss: 8.3004\tlr: 0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5001/8025 [10:01<4:13:55,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   5000\ttrain loss: 7.2292\tval loss: 8.1905\tlr: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 6001/8025 [11:59<2:48:06,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   6000\ttrain loss: 7.1819\tval loss: 8.0969\tlr: 0.000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 7001/8025 [13:57<1:25:17,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   7000\ttrain loss: 7.1858\tval loss: 8.0393\tlr: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 8001/8025 [15:55<02:00,  5.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   8000\ttrain loss: 7.1346\tval loss: 8.0223\tlr: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8025/8025 [16:10<00:00,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   8025\ttrain loss: 7.3519\tval loss: nan\tlr: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8025/8025 [16:31<00:00,  8.10it/s]\n",
      "Parameter 'function'=<function evaluate_tokenized_dataset.<locals>.<lambda> at 0x7fa16fc52fc0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b900ea7dca64a389f1fa3a5ced58241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7d5df6c3134d12a4f201dfb1841cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff80630e5a445caa0289f66cd04fcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0332244a1f47fdac7d7d5255287d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d783c85be8448284bf3466a056a71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae76b8186bdb47a098e9ee73ddf61126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded3e0cf984649e19c8d016bbea20244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a756c14f3e494985b1250534809e944b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96beade38786401baba507989022ace8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16631e0f81b405fb3c697a527d82db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90a7c706ccb44048169f8825258720e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8573d4ccd6324bfd9f218ab52722c316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_generative_loss</td><td>█▂▁▁▁▁▁▁▁</td></tr><tr><td>avg_rationale_loss</td><td>█▅▃▂▂▁▁▁▁</td></tr><tr><td>avg_train_loss</td><td>█▂▁▁▁▁▁▁▁</td></tr><tr><td>avg_yng_loss</td><td>█▂▁▁▁▁▁▁▁</td></tr><tr><td>checkpoint_counter</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>generative_loss</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▁▂▂▁▂▂▂▂▁▂▂▂▃▂▃▂▂</td></tr><tr><td>lr</td><td>▁▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>rationale_loss</td><td>████▇▇▇▆▅▄▅▅▆▅▅▆▅▄▄▄▄▅▅▂▅▆▇▅▃▆▃▃▄▃█▁▄▃▆▂</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▁▂▂▂▃▂▃▂▂</td></tr><tr><td>val_generative_loss</td><td>█▅▅▄▃▂▁▁ </td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▁▁ </td></tr><tr><td>val_rationale_loss</td><td>█▄▃▂▂▁▁▁ </td></tr><tr><td>val_yng_loss</td><td>█▄▃▂▂▁▁▁▁</td></tr><tr><td>yng_loss</td><td>█▆▅▄▄▃▄▃▃▂▂▂▂▂▁▃▂▃▁▃▃▁▂▃▂▂▁▂▂▁▂▁▂▃▂▃▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_generative_loss</td><td>4.10071</td></tr><tr><td>avg_rationale_loss</td><td>0.64403</td></tr><tr><td>avg_train_loss</td><td>7.35191</td></tr><tr><td>avg_yng_loss</td><td>0.26382</td></tr><tr><td>checkpoint_counter</td><td>7</td></tr><tr><td>generative_loss</td><td>3.92802</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>rationale_loss</td><td>0.64544</td></tr><tr><td>train_loss</td><td>6.4788</td></tr><tr><td>val_generative_loss</td><td>nan</td></tr><tr><td>val_loss</td><td>nan</td></tr><tr><td>val_rationale_loss</td><td>nan</td></tr><tr><td>val_yng_loss</td><td>0.24654</td></tr><tr><td>yng_loss</td><td>0.12289</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-haze-15</strong> at: <a href='https://wandb.ai/matteo-periani/nlp_assignment2/runs/wr5hrgdm' target=\"_blank\">https://wandb.ai/matteo-periani/nlp_assignment2/runs/wr5hrgdm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230825_174752-wr5hrgdm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=CONFIG.wandbConfig.project, config=hyperparameters):\n",
    "    config = wandb.config\n",
    "\n",
    "    set_seed(config.seed)\n",
    "\n",
    "    # Make the model\n",
    "    tokenizer, model = make_model(config)\n",
    "\n",
    "    # Make the data\n",
    "    train_data = get_data(\"train\", config).shuffle(42)\n",
    "    # .select(range(1000))\n",
    "    val_data = get_data(\"validation\", config).shuffle(42)\n",
    "    # .select(range(64))\n",
    "    train_dataloader = make_dataloader(train_data, tokenizer, config, split=\"train\")\n",
    "    val_dataloader = make_dataloader(val_data, tokenizer, config, split=\"validation\")\n",
    "\n",
    "    # Make the loss, the optimizer and the scheduler\n",
    "    loss_fn = make_loss(config)\n",
    "    optimizer = make_optimizer(model, loss_fn, config)\n",
    "    scheduler = make_scheduler(\n",
    "        optimizer, steps_per_epoch=len(train_dataloader), config=config\n",
    "    )\n",
    "\n",
    "    # model, train_dataloader, val_dataloader, loss_fn, optimizer, scheduler, metrics = make(config)\n",
    "    print(model)\n",
    "\n",
    "    tf_scheduler = Linear(1., 0.7, total_iters=len(train_dataloader)*config.num_epochs)\n",
    "    train(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        config,\n",
    "        teacher_force_scheduler=tf_scheduler\n",
    "    )\n",
    "\n",
    "    results = evaluate(model, tokenizer, train_data, val_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-attention has been initialized with self-attention weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/matteo/uni/nlp/nlp_assignment2/data/train/train_no_history/distil_roberta/train/cache-ab470769452d68a0.arrow\n",
      "Loading cached shuffled indices for dataset at /home/matteo/uni/nlp/nlp_assignment2/data/train/train_no_history/distil_roberta/validation/cache-af0cd39b307b0fc7.arrow\n",
      "Loading cached shuffled indices for dataset at /home/matteo/uni/nlp/nlp_assignment2/data/train/train_no_history/distil_roberta/test/cache-938ad0729f6b150d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function evaluate_tokenized_dataset.<locals>.<lambda> at 0x7f21e58d04a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e1b2b14a1a402abff5f32b0f91357c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdb0492c8384bb696f7a67e597d1a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d774da5bfe14f27b54503b9e880281f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2718479c3f64adfa2d00c434ff9ec8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fe0e38351d4e34b79138986ca201d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  val\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f10f726350049cf868680ce658623c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc31aa28be3b4911aaccdda529ee78ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a047750baa9647cfa1480c70fca65e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315e3719a5d94b6eaf509ad282cf1f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4700353670f94050ae970bedd64eaccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e51c76182bf483ba17f5233cb36b086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a6599ed0c546c0b8f2c60f7816f437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a09c21ee3d5436f8f2e3c423880770b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2e03d2af6c4838a61eaef46649171a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6271dbdbd04f0aa1d03390bd1565ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Evaluating train set: \u001b[0m\n",
      "Example of Q&A generated:\n",
      "A_pred: Nine\n",
      "A_true: kidnapping\n",
      "\n",
      "A_pred: Emily's account for the the gravestone\n",
      "A_true: the London commissions\n",
      "\n",
      "A_pred: Carrie\n",
      "A_true: Carrie Underwood\n",
      "\n",
      "A_pred: yes\n",
      "A_true: Yes\n",
      "\n",
      "A_pred: no\n",
      "A_true: Yes\n",
      "\n",
      "YesNoGen head f1: tensor([0.8342, 0.8776, 0.9832], device='cuda:0') %\n",
      "YesNoGen head macro-f1: 89.83 %\n",
      "Rationale f1: 63.60 %\n",
      "SQUAD-f1: 35.51 %\n",
      "______________________________\n",
      "\n",
      "\u001b[1m Evaluating val set: \u001b[0m\n",
      "Example of Q&A generated:\n",
      "A_pred: Two\n",
      "A_true: each month\n",
      "\n",
      "A_pred: Never\n",
      "A_true: swim across\n",
      "\n",
      "A_pred: Marco Rubio\n",
      "A_true: the public\n",
      "\n",
      "A_pred: provprovan War War\n",
      "A_true: With the pontoon train\n",
      "\n",
      "A_pred: Captain Horn\n",
      "A_true: It concerns him\n",
      "\n",
      "YesNoGen head f1: tensor([0.6220, 0.6429, 0.9881], device='cuda:0') %\n",
      "YesNoGen head macro-f1: 75.10 %\n",
      "Rationale f1: 63.34 %\n",
      "SQUAD-f1: 30.37 %\n",
      "______________________________\n",
      "\n",
      "\u001b[1m Evaluating test set: \u001b[0m\n",
      "Example of Q&A generated:\n",
      "A_pred: yes\n",
      "A_true: yes\n",
      "\n",
      "A_pred: 11 million\n",
      "A_true: over 11 million\n",
      "\n",
      "A_pred: no\n",
      "A_true: no\n",
      "\n",
      "A_pred: no\n",
      "A_true: No\n",
      "\n",
      "A_pred: 11 minutes\n",
      "A_true: with a prayer\n",
      "\n",
      "YesNoGen head f1: tensor([0.6414, 0.6267, 0.9819], device='cuda:0') %\n",
      "YesNoGen head macro-f1: 75.00 %\n",
      "Rationale f1: 64.59 %\n",
      "SQUAD-f1: 32.23 %\n",
      "______________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = make_model(hyperparameters)\n",
    "model.load_state_dict(torch.load(\"checkpoints/distil_roberta_42_nh_2.pt\"))\n",
    "\n",
    "set_size = 1000\n",
    "train_set = get_data(\"train\", hyperparameters).shuffle(42)\n",
    "val_set = get_data(\"validation\", hyperparameters).shuffle(42)\n",
    "test_set = get_data(\"test\", hyperparameters).shuffle(42)\n",
    "\n",
    "if set_size is not None:\n",
    "    train_set = train_set.select(range(set_size))\n",
    "    val_set = val_set.select(range(set_size))\n",
    "    test_set = test_set.select(range(set_size))\n",
    "\n",
    "results = evaluate(model, tokenizer, train_set, val_set, test_set, hyperparameters)\n",
    "\n",
    "print()\n",
    "for key, (data, res)in results.items():\n",
    "    print(f\"\\033[1m Evaluating {key} set: \\033[0m\")\n",
    "\n",
    "    print(\"Example of Q&A generated:\")\n",
    "    for i in range(5):\n",
    "        print(\"A_pred:\", data[\"pred_answer\"][i])\n",
    "        print(\"A_true:\", data[\"answer\"][i])\n",
    "        print()\n",
    "\n",
    "    print(f\"YesNoGen head f1: {res['yng_f1']} %\")\n",
    "    print(f\"YesNoGen head macro-f1: {res['yng_f1_macro']*100:.2f} %\")\n",
    "    print(f\"Rationale f1: {res['rationales_f1']*100:.2f} %\")\n",
    "    print(f\"SQUAD-f1: {res['answers_squad_f1']*100:.2f} %\")\n",
    "    print(\"_\"*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(results[\"train\"][0][\"yng_label\"], results[\"train\"][0][\"pred_yng_label\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"yes\", \"no\", \"generative\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96edbab9a6341fa88af6e2abcdbd0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecef5b037414767a33e377d09901ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce732d900680459ab682327cd291fdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ec83b1e58745fb967f97ba0a2032b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c656bb342fc04e9faee46f2d04b11736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f56a236b4d4c5c9cd18e1c55f2dd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/miniconda3/envs/nlp/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/matteo/miniconda3/envs/nlp/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  val\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b99548cc9c4bebb0dab2590f7bcc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4165dc487f4ae58e7df0a2c89d1cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fae15aceba44460aa1c2f86a1e57c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8cd634aa424fb09f7ada1d9480be4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1660540e6ce4a47a2c98e36ca4d997c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059244fd23c0415a8942faf90aac26e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae41bd879b4947379a44988083a82e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f717d1de4f4133b5918d4839c269ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4467bc33b14eb5a92cc6a7cd86bd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2798397dbb224887ba6a30640f00e2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a6f1dc697f4f428523672daada91d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e23b8e503148a79a5f8261090760c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEvaluating train set: \u001b[0m\n",
      "\n",
      "Example of Q&A generated:\n",
      "Q: How did they greet?\n",
      "A_pred: a tree\n",
      "A_true: The two men shook hands\n",
      "\n",
      "Q: what?\n",
      "A_pred: she started\n",
      "A_true: gloves\n",
      "\n",
      "Q: Are they proud?\n",
      "A_pred: yes\n",
      "A_true: Yes\n",
      "\n",
      "Q: How many terms did he serve?\n",
      "A_pred: two\n",
      "A_true: Three\n",
      "\n",
      "Q: What was her opponent ranked?\n",
      "A_pred: two\n",
      "A_true: Fourth\n",
      "\n",
      "Total train dataset SQUAD-f1: 0.08\n",
      " - yes_ans_f1 = 1.00 (6.0 %)\n",
      " - no_ans_f1 = 0.00 (4.0 %)\n",
      " - mc_quest_f1 = nan (0.0 %)\n",
      " - wh_quest_f1 = 0.01 (81.0 %)\n",
      "______________________________\n",
      "\n",
      "\u001b[1mEvaluating val set: \u001b[0m\n",
      "\n",
      "Example of Q&A generated:\n",
      "Q: How often?\n",
      "A_pred: five\n",
      "A_true: each month\n",
      "\n",
      "Q: How?\n",
      "A_pred: a summer\n",
      "A_true: swim across\n",
      "\n",
      "Q: Who will decide the outcome of the election?\n",
      "A_pred: president\n",
      "A_true: the public\n",
      "\n",
      "Q: With what?\n",
      "A_pred: two\n",
      "A_true: With the pontoon train\n",
      "\n",
      "Q: How does Horn feel about the plan?\n",
      "A_pred: a boat\n",
      "A_true: It concerns him\n",
      "\n",
      "Total val dataset SQUAD-f1: 0.08\n",
      " - yes_ans_f1 = 1.00 (7.0 %)\n",
      " - no_ans_f1 = 0.00 (8.0 %)\n",
      " - mc_quest_f1 = nan (0.0 %)\n",
      " - wh_quest_f1 = 0.02 (82.0 %)\n",
      "______________________________\n",
      "\n",
      "\u001b[1mEvaluating test set: \u001b[0m\n",
      "\n",
      "Example of Q&A generated:\n",
      "Q: Did Stanley want to shake hands?\n",
      "A_pred: yes\n",
      "A_true: yes\n",
      "\n",
      "Q: How many?\n",
      "A_pred: germany\n",
      "A_true: over 11 million\n",
      "\n",
      "Q: Is he dumber than most film heroes?\n",
      "A_pred: yes\n",
      "A_true: no\n",
      "\n",
      "Q: Did he testify when he was the subject of a suit?\n",
      "A_pred: yes\n",
      "A_true: No\n",
      "\n",
      "Q: How does the recording start?\n",
      "A_pred: 11\n",
      "A_true: with a prayer\n",
      "\n",
      "Total test dataset SQUAD-f1: 0.10\n",
      " - yes_ans_f1 = 1.00 (8.0 %)\n",
      " - no_ans_f1 = 0.00 (11.0 %)\n",
      " - mc_quest_f1 = nan (0.0 %)\n",
      " - wh_quest_f1 = 0.02 (80.0 %)\n",
      "______________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'tokenizer' not in locals() or 'model' not in locals():\n",
    "    tokenizer, model = make_model(hyperparameters)\n",
    "    model.load_state_dict(torch.load(\"checkpoints/bert_tiny_42_nh.pt\"))\n",
    "\n",
    "set_size = 100\n",
    "if 'train_set' not in locals(): train_set = datasets.load_from_disk(CONFIG.dataset.processed_dir, )[\"train\"].shuffle(42)\n",
    "if 'val_set' not in locals(): val_set = datasets.load_from_disk(CONFIG.dataset.processed_dir)[\"validation\"].shuffle(42)\n",
    "if 'test_set' not in locals(): test_set = datasets.load_from_disk(CONFIG.dataset.processed_dir)[\"test\"].shuffle(42)\n",
    "\n",
    "if set_size is not None:\n",
    "    train_set = train_set.select(range(set_size))\n",
    "    val_set = val_set.select(range(set_size))\n",
    "    test_set = test_set.select(range(set_size))\n",
    "\n",
    "results = evaluate(model, tokenizer, train_set, val_set, test_set, hyperparameters)\n",
    "\n",
    "print()\n",
    "for key, (data, res)in results.items():\n",
    "    print(f\"\\033[1mEvaluating {key} set: \\033[0m\\n\")\n",
    "\n",
    "    print(\"Example of Q&A generated:\")\n",
    "    for i in range(5):\n",
    "        print(\"Q:\", data[\"question\"][i])\n",
    "        print(\"A_pred:\", data[\"pred_answer\"][i])\n",
    "        print(\"A_true:\", data[\"answer\"][i])\n",
    "        print()\n",
    "\n",
    "    tot_squad_f1 = res.pop(\"tot_squad_f1\")\n",
    "\n",
    "    print(f\"Total {key} dataset SQUAD-f1: {tot_squad_f1[0]:.2f}\")\n",
    "\n",
    "    for k,v in res.items():\n",
    "        print(f\" - {k} = {v[0]:.2f} ({v[1]:.1f} %)\")\n",
    "\n",
    "    print(\"_\"*30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPassage: \u001b[0mLos Angeles (CNN) -- A man convicted of stalking singer Madonna, and who once threatened to knife her, was arrested Friday, a week after he escaped from a Southern California mental hospital, police said. \n",
      "\n",
      "Robert Dewey Hoskins, 54, had walked away from Metropolitan State Hospital in the Los Angeles suburb of Norwalk on February 3, police said. \n",
      "\n",
      "He had served a 10-year prison sentence for stalking the \"Material Girl,\" police said, and a court order requires him to be in a facility receiving mental health treatment until the end of August 2012. \n",
      "\n",
      "Los Angeles Police Sgt. Mitzi Fierro told HLN's Nancy Grace that she hadn't been told whether any new charges will be filed against Hoskins. \n",
      "\n",
      "\"At this point they are returning him to the facility, and I believe that will be determined by the detectives who will investigate -- number one, his ability to walk away from the facility and, number two, if he violated anything from that point on,\" Fierro said. \n",
      "\n",
      "The facility he was in is not secured, and it was unclear Friday whether Hoskins escaped or walked out on his own, investigators told CNN. \n",
      "\n",
      "He was receiving treatment to get acclimated to society again and was supervised by a civilian staff and not officers, detectives said. \n",
      "\n",
      "Because of the court order, Hoskins was deemed an \"escapee,\" detectives said. \n",
      "\n",
      "Investigators had been looking for him in the Long Beach area because some of his arrest records come from that community, detectives said. \n",
      "\n",
      "Prior to his arrest Friday, Los Angeles police issued a warning to the public saying Hoskins \"is highly psychotic when not taking his medication and has very violent tendencies.\" \n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWho was arrested?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma hospital\n",
      "\u001b[1mAnswer: \u001b[0mRobert Dewey Hoskins,\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mDid he escape from anywhere?\n",
      "\u001b[1mPredicted Answer: \u001b[0myes\n",
      "\u001b[1mAnswer: \u001b[0mA mental hospital\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWhen?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma prison\n",
      "\u001b[1mAnswer: \u001b[0mA week before Friday.\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWhat was he charged with?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma hospital\n",
      "\u001b[1mAnswer: \u001b[0mStalking.\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWho?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma hospital\n",
      "\u001b[1mAnswer: \u001b[0mMadonna\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWho is the police sergeant in Los Angeles?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma hospital\n",
      "\u001b[1mAnswer: \u001b[0mMitzi Fierro\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWas the mental health facility secured?\n",
      "\u001b[1mPredicted Answer: \u001b[0myes\n",
      "\u001b[1mAnswer: \u001b[0mNo.\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWhat was he getting help with?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma hospital\n",
      "\u001b[1mAnswer: \u001b[0mbeing acclimated to society again.\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWas he watched over by police?\n",
      "\u001b[1mPredicted Answer: \u001b[0myes\n",
      "\u001b[1mAnswer: \u001b[0mNo.\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWho then?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma hospital\n",
      "\u001b[1mAnswer: \u001b[0mCivilian staff.\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWhere were police looking for him at?\n",
      "\u001b[1mPredicted Answer: \u001b[0mtwo\n",
      "\u001b[1mAnswer: \u001b[0mthe Long Beach area.\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWas he considered harmless?\n",
      "\u001b[1mPredicted Answer: \u001b[0myes\n",
      "\u001b[1mAnswer: \u001b[0mNo\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mHow old is he?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma hospital\n",
      "\u001b[1mAnswer: \u001b[0m54\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mHow long was he in prison for?\n",
      "\u001b[1mPredicted Answer: \u001b[0ma hospital\n",
      "\u001b[1mAnswer: \u001b[0m10 years\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWhich tv anchor was Fierro speaking too?\n",
      "\u001b[1mPredicted Answer: \u001b[0m30\n",
      "\u001b[1mAnswer: \u001b[0mNancy Grace\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mQuestion: \u001b[0mWill new charges be filed?\n",
      "\u001b[1mPredicted Answer: \u001b[0myes\n",
      "\u001b[1mAnswer: \u001b[0mDid not indicate any.\n",
      "\u001b[1mAnswer SQUAD-f1: \u001b[0m0.0\n",
      "\n",
      "\u001b[1mConversation SQUAD-f1: \u001b[0m0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(conversations_results)):\n\u001b[1;32m     14\u001b[0m     print_conversation(conversations_results[\u001b[39m\"\u001b[39m\u001b[39mpassage\u001b[39m\u001b[39m\"\u001b[39m][i], conversations_results[\u001b[39m\"\u001b[39m\u001b[39mquestions\u001b[39m\u001b[39m\"\u001b[39m][i], conversations_results[\u001b[39m\"\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m\"\u001b[39m][i],\n\u001b[1;32m     15\u001b[0m                         conversations_results[\u001b[39m\"\u001b[39m\u001b[39mpredicted_answers\u001b[39m\u001b[39m\"\u001b[39m][i], conversations_results[\u001b[39m\"\u001b[39m\u001b[39manswers_f1_scores\u001b[39m\u001b[39m\"\u001b[39m][i],\n\u001b[1;32m     16\u001b[0m                         conversations_results[\u001b[39m\"\u001b[39m\u001b[39mconversation_f1_score\u001b[39m\u001b[39m\"\u001b[39m][i])\n\u001b[0;32m---> 17\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "if 'tokenizer' not in locals() or 'model' not in locals():\n",
    "    tokenizer, model = make_model(hyperparameters)\n",
    "    model.load_state_dict(torch.load(\"checkpoints/bert_tiny_42_nh.pt\"))\n",
    "\n",
    "if 'dataset' not in locals(): dataset = datasets.load_from_disk(CONFIG.dataset.filtered_dir).shuffle(42)\n",
    "\n",
    "df_test = pd.DataFrame(dataset[\"test\"]).iloc[:10]\n",
    "\n",
    "for source, df in df_test.groupby(by=['source']):\n",
    "    conversations_results = pd.DataFrame(evaluate_conversation(model, tokenizer, df))\n",
    "    conversations_results = conversations_results.sort_values(by='conversation_f1_score', ascending=True, inplace=False).iloc[:5, :].reset_index(drop=True)\n",
    "    # print(conversations_results)\n",
    "    for i in range(len(conversations_results)):\n",
    "        print_conversation(conversations_results[\"passage\"][i], conversations_results[\"questions\"][i], conversations_results[\"answers\"][i],\n",
    "                            conversations_results[\"predicted_answers\"][i], conversations_results[\"answers_f1_scores\"][i],\n",
    "                            conversations_results[\"conversation_f1_score\"][i])\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
